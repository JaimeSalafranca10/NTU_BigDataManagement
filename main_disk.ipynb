{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "712aadbd",
   "metadata": {},
   "source": [
    "## BIG DATA MANAGEMENT STEP 2: Implementation of a disk memory reducing main memory size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed907545",
   "metadata": {},
   "source": [
    "In the previous part we used a model where the main memory was big enough to process all the data. THis would be the easier case in the implementation. As the instructions tell us we are now implementing a model where we simulate a shorter main memory and hence we create files simulatting the disk memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79495c91",
   "metadata": {},
   "source": [
    "### Usefull functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70d3dcf",
   "metadata": {},
   "source": [
    "We are going to import some packages and create some usefull dictionaries and functions that will make our life easier when implementing more complicated functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb62014c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "import csv\n",
    "from typing import List, Dict, Tuple, Set, Union\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb5a62d",
   "metadata": {},
   "source": [
    "##### We create functions for reading the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9e05ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is just for close the opened files.\n",
    "def close_files(opened_files):\n",
    "    for file in opened_files:\n",
    "        file.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc48bd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function deletes files if existing and recreates the directory\n",
    "def recreate_folders(folders):\n",
    "    for folder in folders:\n",
    "        if os.path.exists(folder) and os.path.isdir(folder):\n",
    "            shutil.rmtree(folder)\n",
    "        os.makedirs(folder)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6719488a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function return the columns of the data set.\n",
    "def get_columns(file):\n",
    "    return open(file, 'r').readline().rstrip().split(',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d830c71",
   "metadata": {},
   "source": [
    "#### We create usefull dictionaries in order to convert easily between the matric numbers and the corresponding information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641be446",
   "metadata": {},
   "source": [
    "As we already explained in part one this dictionaries to map the information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adce5a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_matric = {4:\"2014\",5: \"2015\",6: \"2016\",7:\"2017\",8:\"2018\",9:\"2019\",0:\"2000\",1:\"2001\",2:\"2002\",3:\"2003\"}\n",
    "town_matric = {0: \"ANG MO KIO\", 1:\"BEDOK\", 2:\"BUKIT BATOK\", 3:\"CLEMENTI\", 4:\"CHOA CHU KANG\", 5:\"HOUGANG\", 6:\"JURONG WEST\", 7:\"PUNGGOL\", 8:\"WOODLANDS\", 9:\"YISHUN\"}\n",
    "month_matric = {0: \"10\", 1:\"11\", 2:\"12\", 3:\"01\", 4:\"02\", 5:\"03\", 6:\"04\",7:\"05\", 8:\"06\", 9:\"07\",10:\"08\", 11:\"09\"}\n",
    "value_dict = {0:\"Minimum Area\", 1:\"Average Area\", 2:\"Standard Deviation of Area\", 3:\"Minimum Price\", 4:\"Average Price\", 5:\"Standard Deviation of Price\"}\n",
    "MAP_TOWN = {'town': {'ANG MO KIO': 0,'BEDOK': 1,'BUKIT BATOK': 2,'CLEMENTI': 3,'CHOA CHU KANG': 4,'HOUGANG': 5,'JURONG WEST': 6,'PUNGGOL': 7,'WOODLANDS': 8,'YISHUN': 9}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f46e68",
   "metadata": {},
   "source": [
    "#### We create the useful variables and names of the files that we will create after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44b9d091",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"ResalePricesSingapore.csv\"\n",
    "cols = [\"month\", \"town\", \"resale_price\", \"floor_area_sqm\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46ae995",
   "metadata": {},
   "source": [
    "This value is very important because it sets the value of the main memory, and creates diferent arrays with the information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d933a706",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LINE = 50000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7881e1",
   "metadata": {},
   "source": [
    "We also create the name of the folders that we will use in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7066ae3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMP = 'temp'\n",
    "ARCHIVE_FOLDER = 'archive'\n",
    "RESULTS_FOLDER = \"result\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee52c1e",
   "metadata": {},
   "source": [
    "### Preprocessing of the data set and reation of the disk storage:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221377ef",
   "metadata": {},
   "source": [
    "In this part of the work we will preoprocess the data. This is receiving the matric numbers as information. With this we have to create the different columns in separated files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7caf93d",
   "metadata": {},
   "source": [
    "### We will need to:\n",
    "    \n",
    "       - create a dictionary that stres the columns idexes and date for each zone map."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32de0870",
   "metadata": {},
   "source": [
    "When looking to the data, we found out that the data was sorted. In fact, the sorting is done in the column month. This could be used after for extracting the indexes corresponding for the date query. That is why for each zone_map we want to store the indexes for maximum and minimum values such as the date for those values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "118a580f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We initialize the dictionary for the zone_maps that will store the max and min date and indexes.\n",
    "# This is very usefull for the the rest of the prgram as the data is sorted in function of the month column.\n",
    "def init_zones_dict(zone_maps):\n",
    "    min_date = '9999-01'\n",
    "    max_date = '0000-01'\n",
    "    zonedict = {\n",
    "        col: {\n",
    "            'min_idx': float('inf'),\n",
    "            'max_idx':-float('inf')\n",
    "        }\n",
    "        for col in zone_maps\n",
    "    }\n",
    "    if 'month' in zone_maps:\n",
    "            zonedict['month']['min_date'] = min_date\n",
    "            zonedict['month']['max_date'] = max_date\n",
    "\n",
    "    return zonedict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "211ad2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function just stores the zone maps and the reinitialize the dictionnary\n",
    "def store_in_zone_map(zonemaps_dict,zone_maps):\n",
    "    for col in zone_maps: \n",
    "        if col in cols:\n",
    "            zone_maps[col].append(zonemaps_dict[col])\n",
    "    zonemaps_dict = init_zones_dict(zone_maps)\n",
    "    return zone_maps, zonemaps_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a475ce",
   "metadata": {},
   "source": [
    "This function goes through all the data reading line by line. We read it this way because is the most confortable way of reading a csv file. We store the values of the columns, the one we think are interesting for us. We simulate arrays of the maximum size of the main memory we setted. We update the values of the maximum and minimum indexes and date of the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aaa740af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_columns(file, zone_maps):\n",
    "    # We get all the columns of the data.\n",
    "    columns = get_columns(file)\n",
    "    recreate_folders([\"split_data\"])\n",
    "    opened_files = []\n",
    "    \n",
    "    \n",
    "    with open(file, 'r') as f:\n",
    "        next(f)\n",
    "        zonemaps_dict = init_zones_dict(zone_maps)\n",
    "        curr_zone = 0\n",
    "        i = 0\n",
    "        \n",
    "        # For each line of the data set:\n",
    "        for line in f:\n",
    "\n",
    "            # In the case that the data line is the last one of the array:\n",
    "            if i % MAX_LINE == MAX_LINE - 1:\n",
    "                for col in zonemaps_dict:\n",
    "                    # We store the index as the bigger index\n",
    "                     zonemaps_dict[col]['max_idx'] = i\n",
    "                        \n",
    "            # In the case thet the line is the first of the disk array:            \n",
    "            if i % MAX_LINE == 0:\n",
    "                if opened_files:\n",
    "                    # We store the values and just return the zone maps.\n",
    "                    zone_maps, zonemaps_dict = store_in_zone_map(zonemaps_dict,zone_maps)\n",
    "                    close_files(opened_files)\n",
    "                # We also store the minimum values of the indexes    \n",
    "                for col in zonemaps_dict:\n",
    "                    zonemaps_dict[col]['min_idx'] = i\n",
    "                # We open the files where we store the values.\n",
    "                opened_files = [\n",
    "                    open(f'split_data/{col}_{curr_zone}.txt', 'w')\n",
    "                    for col in columns if col in cols\n",
    "                ]\n",
    "                curr_zone += 1\n",
    "            \n",
    "            # We store the values of the interesting files in the corresponding files\n",
    "            content = line.rstrip().split(',')\n",
    "            if content[1] in MAP_TOWN['town']:\n",
    "                c1 = str(MAP_TOWN['town'][content[1]])\n",
    "                c2 = content[0]\n",
    "                c3 = content[6]\n",
    "                c4 = content[9]\n",
    "                min_date = zonemaps_dict['month']['min_date']\n",
    "                max_date = zonemaps_dict['month']['max_date']\n",
    "                zonemaps_dict['month']['min_date'] = min(min_date, content[0])\n",
    "                zonemaps_dict['month']['max_date'] = max(max_date, content[0])\n",
    "                opened_files[1].write(f'{c1}\\n')\n",
    "                opened_files[0].write(f'{c2}\\n')\n",
    "                opened_files[2].write(f'{c3}\\n')\n",
    "                opened_files[3].write(f'{c4}\\n')\n",
    "            i += 1\n",
    "            \n",
    "            \n",
    "    # We update the maps.        \n",
    "    for col in zonemaps_dict:\n",
    "        zonemaps_dict[col]['max_idx'] = i - 1\n",
    "    zone_maps, zonemaps_dict = store_in_zone_map(zonemaps_dict,zone_maps)\n",
    "    close_files(opened_files)\n",
    "    return zone_maps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef36ddc",
   "metadata": {},
   "source": [
    "We create a function to store the values of the corresponding dates of the years and months. In some cases, we have to take into account that the years have to be respectivelly updated when increasing the months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bbc3684",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_dates (n_year1, n_month1):\n",
    "    n_month2 = (n_month1 + 1) % 12\n",
    "    n_month3 = (n_month1 + 2) % 12\n",
    "    n_year2 = n_year1\n",
    "    n_year3 = n_year2\n",
    "\n",
    "    if n_month1 == 1:\n",
    "        n_year3 = n_year1 +1\n",
    "    if n_month1 == 2:\n",
    "        n_year3 = n_year1 +1\n",
    "        n_year2 = n_year1 +1\n",
    "    \n",
    "    required_years = [n_year1, n_year2, n_year3]\n",
    "    required_month = [month_matric[n_month1], month_matric[n_month2],month_matric[n_month3]]\n",
    "    return required_years, required_month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b9af65",
   "metadata": {},
   "source": [
    "### FUNCTIONS FOR PROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ccf717",
   "metadata": {},
   "source": [
    "Here we are going to create all the function that will enable us to retrieve the data. \n",
    "<ul>\n",
    "    <li>First all the indexes corresponding to the query months will be retrieved.</li>\n",
    "<li>Then among those data indexes we will find which ones have as city the one in the query</li>\n",
    "<li>Then among the indexes we will compute the values we need.</li></ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf54075",
   "metadata": {},
   "source": [
    "#### Searching for the indexes of the correct years\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d416e29",
   "metadata": {},
   "source": [
    "The objective if finding all the indexes of teh data that correspond to the query date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04085a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_search( dt_to_check: str, lines: List[str]) -> int:\n",
    "    \"\"\"Binary search to find smallest position of record in current month\"\"\"\n",
    "    left, right = 0, len(lines) - 1\n",
    "    while left <= right:\n",
    "        mid = (left + right) // 2\n",
    "        mid_value = lines[mid]\n",
    "        if mid_value == dt_to_check:\n",
    "            while mid_value == dt_to_check:\n",
    "                mid -=1\n",
    "                mid_value = lines[mid]\n",
    "            return mid+1\n",
    "        \n",
    "        if mid_value < dt_to_check:\n",
    "            left = mid + 1\n",
    "        else:\n",
    "            right = mid - 1\n",
    "    return left"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e1cd3a",
   "metadata": {},
   "source": [
    "We have to find the indexes so we first find in which zones the dta is stored. We use the function find_zone() to know where the data is stored. Then we will write with the write_year() method all the data in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2fbe0879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given the zone maps and the required months and years we want it to create the corresponding files.\n",
    "\n",
    "def process_month_and_year(required_years,required_month,zone_maps):\n",
    "        dt_to_check1 = f'{required_years[1]}-{required_month[0]}'\n",
    "        dt_to_check2 = f'{required_years[2]}-{required_month[1]}'\n",
    "        dt_to_check3 = f'{required_years[2]}-{required_month[2]}'\n",
    "        dt_to_check = [dt_to_check1, dt_to_check2, dt_to_check3]\n",
    "        zone = find_zone(zone_maps,dt_to_check)\n",
    "        \n",
    "        if zone == -1:\n",
    "            print('Error, could not find date')\n",
    "            return\n",
    "        if not os.path.exists(TEMP):\n",
    "            os.makedirs(TEMP)\n",
    "        opened_files = [open(f'{TEMP}/month_{dt_to_check[0]}_{i}.txt', 'w')\n",
    "                        for i in range(1, 4)]\n",
    "\n",
    "        write_year(zone_maps,zone,opened_files,dt_to_check)\n",
    "        close_files(opened_files)\n",
    "        return dt_to_check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cb5988",
   "metadata": {},
   "source": [
    "This function return the zone of the corresponding date to check only by inspecting teh dictionnary created previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97fe2e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def find_zone(zone_maps, dt_to_check):\n",
    "        zones = []\n",
    "        for zone, min_dict in enumerate(zone_maps['month']):\n",
    "            min_date = min_dict['min_date']\n",
    "            max_date = min_dict['max_date']\n",
    "            if min_date < dt_to_check[0] <= max_date:\n",
    "                zones.append(zone)\n",
    "            if min_date <= dt_to_check[2] <= max_date:\n",
    "                if zone not in zones:\n",
    "                    zones.append(zone)\n",
    "            if min_date <= dt_to_check[2] < max_date:\n",
    "                if zone not in zones:\n",
    "                    zones.append(zone)\n",
    "                return (zones)\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015b3ab8",
   "metadata": {},
   "source": [
    "We use this method to the write the data in the corresponding files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b38ade9",
   "metadata": {},
   "outputs": [],
   "source": [
    "   def write_year(zone_maps,zones,opened_files,dt_to_check):\n",
    "        \n",
    "        for zone in zones:\n",
    "            if zone >= len(list(zone_maps.values())[0]):\n",
    "                return\n",
    "            # We open the file of the corresponding zone\n",
    "            with open(f'split_data/month_{zone}.txt', 'r') as f:\n",
    "                lines = f.read().splitlines()\n",
    "            lowest_idx = 0\n",
    "            # we check for each date \n",
    "            for dt in dt_to_check:\n",
    "                # we use a binary search to find the index where teh data starts.\n",
    "                lowest_idx = binary_search(dt,lines)\n",
    "                #We set the end of the index of the file.\n",
    "                end = MAX_LINE * zone\n",
    "                \n",
    "                for idx in range(lowest_idx, len(lines)):\n",
    "                    line = lines[idx]\n",
    "                    # We check the year\n",
    "                    if int(line[:4]) != int(dt[:4]):\n",
    "                        break\n",
    "                    # we check the month\n",
    "                    if int(line[5:7]) != int(dt[5:7]):\n",
    "                        break\n",
    "                    month = int(line[5:7])\n",
    "                    opened_files[month-1].write(f'{line.split()[0]} {end + idx}\\n')\n",
    "            return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bee7ac9",
   "metadata": {},
   "source": [
    "Now we have obtained all the indexes corresponding of the years. Now we will look for the indexes that also correspond to the town variable also."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba0b382",
   "metadata": {},
   "source": [
    "#### Searching for the indexes of the correct town"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ba9912",
   "metadata": {},
   "source": [
    "We will do the same thing for finding the correct indexes but for the town."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7250810f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def process_location(zone_maps, location):\n",
    "        current_files = ['/'.join([TEMP, f])\n",
    "                         for f in os.listdir(TEMP)]\n",
    "        \n",
    "        for file in current_files:\n",
    "            filename = file.split('/')[-1]\n",
    "            underscore_idx = filename.find('_')\n",
    "            col = filename[:underscore_idx]\n",
    "            remainder = filename[underscore_idx + 1:]\n",
    "            \n",
    "            if col != 'month':\n",
    "                continue\n",
    "            # will read in a list of indexes\n",
    "            town_file = f'{TEMP}/town_{remainder}'\n",
    "            \n",
    "            with open(file, 'r') as f, open(town_file, 'a') as f2:\n",
    "                # we retireve the data previouslly stored in processing year \n",
    "                # we retrieve the index \n",
    "                month_data = f.read().splitlines()\n",
    "                month_data = list(map(split_month, month_data))\n",
    "                starting_idx = month_data[0][1]\n",
    "                ending_idx = month_data[-1][1]\n",
    "                \n",
    "                for zone, zonemaps_dict in enumerate(zone_maps['month']):\n",
    "                    min_idx = zonemaps_dict['min_idx']\n",
    "                    max_idx = zonemaps_dict['max_idx']\n",
    "                    # We check if the starting index is not in zone so we can skip teh processus\n",
    "                    if starting_idx > max_idx:\n",
    "                        continue\n",
    "                    # if we have already pass the data we can skip.\n",
    "                    if ending_idx < min_idx:\n",
    "                        break\n",
    "                        \n",
    "                    with open(f'split_data/town_{zone}.txt', 'r') as f:\n",
    "                        # we read the data \n",
    "                        town_data = f.read().splitlines()\n",
    "                        \n",
    "                    for month_date, month_idx in month_data:\n",
    "                        if month_idx not in range(min_idx, max_idx + 1):\n",
    "                            continue\n",
    "                        if  month_idx >= starting_idx and month_idx <= ending_idx:\n",
    "                            #We check the town is the same than the location one\n",
    "                            if int(town_data[month_idx]) == int(location):\n",
    "                                f2.write(f'{month_date} {month_idx}\\n')\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ab0245",
   "metadata": {},
   "source": [
    "The following method will be used return the date and the index separatelly for a given string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7367a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_month(s):\n",
    "    date_idx = s.rstrip().split()\n",
    "    # we convert it to an integer.\n",
    "    date_idx[1] = int(date_idx[1])\n",
    "    return date_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5a2c8f",
   "metadata": {},
   "source": [
    "We now have all the values of indexes for the correct town and month of the query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9736d1dc",
   "metadata": {},
   "source": [
    "#### Computing values for the query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3600ed09",
   "metadata": {},
   "source": [
    "This function writes the output after computing the specifical values. We will compute the average and minimum with one single lecture of the columns. For the standard deviation we need to compute first the average so we need to do a second lecture of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e318866",
   "metadata": {},
   "source": [
    "To compute the values of the query first all the values will be initialized. Then as has been done previously the town data is read and the index from the town file. Then we will go along the resale price file and the floor_area_sqm to compute the value for minimum average and standard deviation. For Average and sminimum we will use the same loop doing a dual scanning. We will need to do a second scanning once the average is found to compute the standard deviation. But as we are going to see in the results this second scanning is not very time-consuming. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79f69195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resale_price_and_flat_area_sqm( matric_num, zone_maps):\n",
    "    \n",
    "        file_r = f'ScanResult_{matric_num}.csv'\n",
    "        current_files = ['/'.join([TEMP, f]) for f in os.listdir(TEMP)]\n",
    "        \n",
    "        \n",
    "        for file in current_files[-3:]:\n",
    "            \n",
    "            #We initialize all the values that we will plot.\n",
    "            min_resale_price, min_resale_price_dates = float('inf'), set()\n",
    "            min_floor_area_sqm, min_floor_area_sqm_dates = float('inf'), set()\n",
    "            sum_resale_price, sum_floor_area_sqm = 0,0\n",
    "            avg_resale_price, avg_floor_area_sqm = 0,0\n",
    "            sd_resale_price, sd_floor_area_sqm = 0,0\n",
    "            count = 0\n",
    "            \n",
    "            with open(file, 'r') as f:\n",
    "                town_data = f.read().splitlines()\n",
    "                \n",
    "            \n",
    "                if not town_data:\n",
    "                    continue\n",
    "                # We split the data to get the index of beggining and end.\n",
    "                \n",
    "                town_data = list(map(split_month, town_data))\n",
    "                start = town_data[0][1]\n",
    "                end = town_data[-1][1]\n",
    "                \n",
    "                for zone, zonemaps_dict in enumerate(zone_maps['resale_price']):\n",
    "                    min_idx = zonemaps_dict['min_idx']\n",
    "                    max_idx = zonemaps_dict['max_idx']\n",
    "                    # as already done before we narrow the search\n",
    "                    if start > max_idx:\n",
    "                        continue\n",
    "                    if end < min_idx:\n",
    "                        break\n",
    "                        \n",
    "                    with open(f'split_data/resale_price_{zone}.txt', 'r') as f:\n",
    "                        resale_price_data = list(\n",
    "                            map(convert_to_float, f.read().splitlines())\n",
    "                        )\n",
    "                    with open(f'split_data/floor_area_sqm_{zone}.txt', 'r') as f:\n",
    "                        flat_area_sqm_data = list(\n",
    "                            map(convert_to_float, f.read().splitlines())\n",
    "                        )\n",
    "                        \n",
    "                    # we do one lecture and compute the minimum and the average.\n",
    "                    for town_date, town_idx in town_data:\n",
    "                        if town_idx not in range(min_idx, max_idx + 1):\n",
    "                            continue\n",
    "                        resale_price = resale_price_data[town_idx - min_idx]\n",
    "                        floor_area_sqm = flat_area_sqm_data[town_idx - min_idx]\n",
    "                        \n",
    "                        min_resale_price, min_resale_price_dates = mini(town_date,resale_price,min_resale_price,min_resale_price_dates)\n",
    "                        min_floor_area_sqm, min_floor_area_sqm_dates = mini(town_date,floor_area_sqm,min_floor_area_sqm,min_floor_area_sqm_dates)\n",
    "                        count+= 1\n",
    "                        avg_resale_price += resale_price\n",
    "                        avg_floor_area_sqm += floor_area_sqm\n",
    "                    \n",
    "                    avg_resale_price = avg_resale_price/count\n",
    "                    avg_floor_area_sqm = avg_floor_area_sqm/count\n",
    "                    \n",
    "                    # we compute now the standard deviation\n",
    "                    for town_date, town_idx in town_data:\n",
    "                        if town_idx not in range(min_idx, max_idx + 1):\n",
    "                            continue\n",
    "                        # We computethe standard deviation\n",
    "                        resale_price = resale_price_data[town_idx - min_idx]\n",
    "                        floor_area_sqm = flat_area_sqm_data[town_idx - min_idx]\n",
    "                        sd_resale_price+= (resale_price - avg_resale_price)**2\n",
    "                        sd_floor_area_sqm+= (floor_area_sqm - avg_floor_area_sqm)**2\n",
    "                    \n",
    "                    sd_resale_price = math.sqrt(sd_resale_price/(count-1))\n",
    "                    sd_floor_area_sqm = math.sqrt(sd_floor_area_sqm/(count-1))\n",
    "                    \n",
    "            write_results(file_r,[min_resale_price, min_resale_price_dates],[min_floor_area_sqm, min_floor_area_sqm_dates],avg_resale_price ,\n",
    "                avg_floor_area_sqm,sd_resale_price, sd_floor_area_sqm)\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49334c6",
   "metadata": {},
   "source": [
    "This function is only used to compute the minimum between two values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7bdb3f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def mini(current_date,current,minimum,date_set):\n",
    "        if current  < minimum:\n",
    "            minimum = current\n",
    "            date_set = set([current_date])\n",
    "        elif current == minimum:\n",
    "            date_set.add(current_date)\n",
    "        return minimum, date_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b553c22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "   def convert_to_float( s: str) -> Union[str, float]:\n",
    "        try:\n",
    "            return float(s)\n",
    "        except ValueError:\n",
    "            return s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b129c5",
   "metadata": {},
   "source": [
    "Finally, we write the results in Excel using the variable query to adjust the results we write in the CSV file to the requirements of the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8fe2546d",
   "metadata": {},
   "outputs": [],
   "source": [
    "   def write_results(file, min_resale_price,min_floor_area_sqm, avg_resale_price,\n",
    "                avg_floor_area_sqm,sd_resale_price, sd_floor_area_sqm):\n",
    "        if not os.path.exists(RESULTS_FOLDER):\n",
    "            os.makedirs(RESULTS_FOLDER)\n",
    "        town = town_matric[location]\n",
    "        stats_and_categories = [\n",
    "            (min_resale_price, 'Min ResalePrice'),\n",
    "            (min_floor_area_sqm, 'Min FloorAreaSqm')]\n",
    "        values = [\n",
    "            (avg_resale_price, 'Avg ResalePrice'),\n",
    "            (avg_floor_area_sqm, 'Avg FloorAreaSqm'),\n",
    "            (sd_resale_price, 'Sd ResalePrice'),\n",
    "            (sd_floor_area_sqm, 'Sd FloorAreaSqm')\n",
    "        ]\n",
    "        file_name = f'{RESULTS_FOLDER}/{file}'\n",
    "        file_exists = os.path.isfile(file_name)\n",
    "        with open(file_name, 'a', newline='') as csv_file:\n",
    "            csv_writer = csv.writer(csv_file, delimiter=',')\n",
    "            if not file_exists:\n",
    "                col_name = ['month', 'town', 'Category', 'Value']\n",
    "                csv_writer.writerow(col_name)  # write col name\n",
    "                \n",
    "            for (stat, dates), category in stats_and_categories:\n",
    "                for date in dates:\n",
    "                    if (query == 1 or query ==0) and category == 'Min ResalePrice':\n",
    "                        stat = round(stat, 2)\n",
    "                        line = [date, town, category, str(stat)]\n",
    "                        csv_writer.writerow(line)\n",
    "                    if (query == 2 or query ==0) and category == 'Min FloorAreaSqm':\n",
    "                        stat = round(stat, 2)\n",
    "                        line = [date, town, category, str(stat)]\n",
    "                        csv_writer.writerow(line)\n",
    "                        \n",
    "            for value, category in values:\n",
    "                if (query == 3 or query ==0) and category == 'Avg ResalePrice':\n",
    "                    value = round(value, 2)\n",
    "                    line = [date, town, category, str(value)]\n",
    "                    csv_writer.writerow(line)\n",
    "                    \n",
    "            for value, category in values:\n",
    "                if (query == 4 or query ==0) and category == 'Avg FloorAreaSqm':\n",
    "                    value = round(value, 2)\n",
    "                    line = [date, town, category, str(value)]\n",
    "                    csv_writer.writerow(line)\n",
    "                    \n",
    "            for value, category in values:\n",
    "                if (query == 5 or query ==0) and category == 'Sd ResalePrice':\n",
    "                    value = round(value, 2)\n",
    "                    line = [date, town, category, str(value)]\n",
    "                    csv_writer.writerow(line)\n",
    "                    \n",
    "            for value, category in values:\n",
    "                if (query == 6 or query ==0) and category == 'Sd FloorAreaSqm':\n",
    "                    value = round(value, 2)\n",
    "                    line = [date, town, category, str(value)]\n",
    "                    csv_writer.writerow(line)\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63aca4a8",
   "metadata": {},
   "source": [
    "#### Running all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f4e7e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(required_years,required_month,zone_maps,location,matric_num):\n",
    "    time3 = time.time()\n",
    "    dt_to_check = process_month_and_year(required_years,required_month,zone_maps)\n",
    "    process_location(zone_maps,location)   \n",
    "    resale_price_and_flat_area_sqm(matric_num, zone_maps)\n",
    "    time4 = time.time()\n",
    "    exec_time2 = time4-time3\n",
    "    print(\"The query task takes :\" , exec_time2 , \" seconds\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1943a5bc",
   "metadata": {},
   "source": [
    "### User interface:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414bc993",
   "metadata": {},
   "source": [
    "In this part of teh script the user will enter his information and query to obtain the respective results. He will also receive all the information about the time taken and the momery occupied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9e590d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data file used: ResalePricesSingapore.csv\n",
      "File Size is 17.07774543762207 MB\n",
      "Number of Lines in the file is 222834\n",
      "ResalePricesSingapore.csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Main interface with user\"\"\"\n",
    "\n",
    "print(f'Data file used: {file}')\n",
    "print(f'File Size is {os.stat(file).st_size / (1024 * 1024)} MB')\n",
    "line_count = sum(1 for _ in open(file, 'r'))\n",
    "print(f'Number of Lines in the file is {line_count}')\n",
    "print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0e3932",
   "metadata": {},
   "source": [
    "We create the zone maps for the different columns the ones that are usefull for our query. Then we use the function create columns to split the data in columns and in different files simulating the disk memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ad7566d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The column splitting in zone maps  takes : 1.0182902812957764  seconds\n"
     ]
    }
   ],
   "source": [
    "zone_maps = {\n",
    "    col: []\n",
    "    for col in cols}\n",
    "time1 = time.time()\n",
    "zone_maps = create_columns(file,zone_maps)\n",
    "time2 = time.time()\n",
    "exec_time1 = time2-time1\n",
    "print(\"The column splitting in zone maps  takes :\", exec_time1 ,\" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb5507e",
   "metadata": {},
   "source": [
    "This interface is just usefull to ask the user about his matric number and then retrieve the usefull digits for its corresponding information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b0d9cdd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your matriculation number for processing, c to cancel: N2303635K\n",
      "Enter query:\n",
      " 0 for everything\n",
      " 1 for Min ResalePrice\n",
      " 2 for Min FloorAreaSqm\n",
      " 3 for Avg ResalePrice\n",
      " 4 for Avg FloorAreaSqm\n",
      " 5 for Sd ResalePrice\n",
      " 6 for Sd FloorAreaSqm        0\n"
     ]
    }
   ],
   "source": [
    "    while True:\n",
    "        print()\n",
    "        text = 'Enter your matriculation number for processing, c to cancel: '\n",
    "        matric_num = input(text).strip()\n",
    "        if matric_num == 'c':\n",
    "            print('Have a good day, bye bye...')\n",
    "            break\n",
    "        n_year1, n_month1,location = year_matric[int(matric_num[-2])], int(matric_num[-3]), int(matric_num[-4])\n",
    "        text = 'Enter query:\\n 0 for everything\\n 1 for Min ResalePrice\\n 2 for Min FloorAreaSqm\\n 3 for Avg ResalePrice\\n 4 for Avg FloorAreaSqm\\n 5 for Sd ResalePrice\\n 6 for Sd FloorAreaSqm        '\n",
    "        query = int(input(text))\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4091f7bd",
   "metadata": {},
   "source": [
    "We compute the dates that we will need doing all the necessary checks using the created functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "26bd2265",
   "metadata": {},
   "outputs": [],
   "source": [
    "required_years, required_month = query_dates(n_year1, n_month1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72f2125",
   "metadata": {},
   "source": [
    "Finally we run everything to complete the instructions of the work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cfe6d511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The query task takes : 0.14081478118896484  seconds\n"
     ]
    }
   ],
   "source": [
    "process(required_years,required_month,zone_maps,location,matric_num)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
